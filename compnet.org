# -*- mode: org; -*-
#+TITLE: Computer Networks
#+SETUPFILE: htmlnotes.setup

* Chapter 1
** Definitions
*** Network
A network is made of
- end-systems (server or client)
- Internet Service Provider (ISP)
- Links
- Switches
*** Acess network
**** Digital Subscriber Line (DSL)
- Uses *existing* telephone line
- *Dedicated* line
**** Cable network
- *Shared* line
**** Enterprise acess networks (ethernet)
- Used by companies/universities
- Instituional link to ISP
- Use of ethernet switches
**** Wireless networks
- Local or wide-area (cellular networks)
*** Protocol
A protocol defines format, order of messages sent and received among network
entities and actions taken on message transmisson/receiption.
*** Packets
- Host divides what he want to send into chunks called *packets* of length $L$
- transmit packet into network at *transmission rate* $R$
*** Routing
Determines source-destination route taken by packets \rightarrow /routing algorithms/
*** Forwading
Move packets from router's input to appropriate router output
*** Switch contents
- Buffers \rightarrow store data
- Forwading table
  - Store meta-data
  - Indicate where to send the data
*** Throughput

Rate (bps) at which bits are transferred between sender/receiver. Depends on the
*bottleneck* link (slowest link). Meaning that the average throughput is equal
to the minimum link bandwith of network.
*** Round-trip time (RTT)
Time it takes for a signal to be sent plus the length of time it takes for an
acknowledgment of that signal to be received.
** Concepts
*** Circuit vs packet switching
| Circuit-switching                                        | Packet-switching                                      |
|----------------------------------------------------------+-------------------------------------------------------|
| resources reserved per active connection                 | Packets treated on demand                             |
| admission control & forwarding decision : per connection | admission control & forwarding decision : per packet  |
| inefficient resource use                                | efficient ressource use                               |
| predictable performance                                  | unpredictable performance                             |
|                                                          | simpler to implement, but requires congestion control |
|                                                          | allow more user to use the network                    |
**** Circuit-switching
- End to end resources reserved for "call" between source and destination
- No sharing : circuit-like (guaranteed) performance
- Twos implemation :
  - Time Division Multiplexing (TDM)
    - Divides time in *time slot*
    - separate time slot per connection (burst at full speed)
  - Frequency Division Multiplexing (FDM)
    - Divide frequency spectrum in *frequency bands*
    - separate frequency band per connection
**** Packet-switching
- Hosts break application-layer messages into packer
  - Forward packets from one routeur to the next, across links on path from
    source to destination
  - Each packet transmitted at *full link capacity*
- *Store and forward* : entire packet must arriver at routeur before it can be
  transmitted on next link
- If arrival rate (bits) to link > transmission rate of link :
  - packet will *queue*, waiting to be transmitted
  - packets can be *dropped* (lost) if buffer fills up
*** Internet organization
[[file:images/compnet_01.png]]
*** Delay
We have that :

d_{nodal} = d_{proc} + d_{queue} + d_{trans} + d_{prop}

- d_{trans} : transmission delay
  - Time needed to push all the bits of a packet into a link
  - L: packet length (bits)
  - R: link bandwidth (bps)
  - d_{trans} = L/R
- d_{prop}: propagation delay
  - Time needed to move one bit from one end of a link to the other
  - d: length of physical link
  - s: propagation speed in medium
  - d_{prop} = d/s
- d_{proc}: nodal processing
  - check bit errors
  - determine output link
  - typically < msec
- d_{queue} : queuing delay
  - time waiting at output link for transmission
  - depends on congestion level of routeur (and burstiness of arrival)
  - statistical mesure
  - Way to analyse :
    - units :
      - L: packet length (bits)
      - R: link bandwidth (bps)
      - a: average packet arrival rate
    - analysis :
      - La/R ~ 0 : average queuing delay *small*
      - La/R ~ 1 : average queuing delay *large*
      - La/R > 1 : more "work" arriving than can be serviced, average queuing
        delay *infinite*
*** Internet  layering
- application : application that exchange *messages*
- transport : transports *segments* between *processes*
- network : move *datagrams* between *hosts*
- link : moves *frames* across a link
- physical : moves data across a physical medium

Advantages :
- reduce complexity
- improve flexibility
*** Security
Different ways of attacking :
- Malware
- Denial of Service (DoS)
- Packet sniffing (eavesdropping)
- Ip spoofing (impersonating)
* Chapter 2
** Application architectures
*** Client-server architecturea
- Clear separation of roles
- Server runs on dedicated infrastrure
*** Peer-to-peer architecture
- A peer may act both as client and server
- Peer runs on personally owned end-system
** Internet transport services
Both offers no security and performance (delay and bandwidth) guarantees
*** TCP
- reliable, in-order message delivery
- "connection-oriented" or "stateful"
- flow and congestion control
- Can be persistent or non-persistent (modern browser \rightarrow persistent)
- Can be one or multiple connection (mordern browser \rightarrow multiple)
*** UDP
- only the adress of the client/server is stored
- doesn't keep any state about the packet
- lost packets are not retransmitted
- used-in time-critical applications
  - voice transmission
  - video chat
** HTTP
- web's application layer protocol
- uses TCP
- Stateles
- Persistent or non persistent
  - non persistent at most one object per connection
  - persistent multiple object sent over one TCP connection
- Request types
  - GET: client requests to download a file
  - POST : client provides information
  - PUT : client requests to upload a file
  - DELETE : client requests to delete a file
- Response types
  - OK
  - Not found
  - Moved permanently
  - Bad request
  - ...
- Cookies
  - state kept by server
  - links previous HTTP requests to the same web client
  - privacy issues, user-tracking
** Web caching
- cache copies of other web-server files
- act as a web server to nearby web clients
- lower bandwidth usage
- Ensure file is fresh with "conditional GET" request
** Web design
- Architecture : client-server architecture
- Communication protocol : HTTP requests & responses
- Transport service : TCP (typically with persistent TCP connections)
** Domain Name Service (DNS)
Hostname to IP adress translation
*** Why not centralize DNS ?
  - single point of failure
  - too much traffic volume
  - cannot be close to all DNS client
  - maintenance
  - *doesn't scale*
*** Hierachy
- root servers
- TLD (top-level domain) servers (e.g. .ch servers)
- authoritative servers (e.g. epfl.ch servers)
*** Local DNS Server
- does not belong to hierachy
- all ISPs have one
- DNS queries are first sent to it
- acts as a proxy : when getting a mapping to an IP it will store it in order to reuse it for other clients
*** Query
**** Recursive query
- puts burden of name resolution on contacted name server
- heavy load at upper levels of hierachy
#+attr_html: :width 500px
[[file:images/compnet_02.png]]
**** Iterative query
- contacted server replies with name of server to contact
- "I don't know this name, but ask this server"
#+attr_html: :width 500px
[[file:images/compnet_03.png]]
*** Caching
- Caching of DNS responses at all levels
- Reduces load at all levels
- Reduces delay experienced by DNS clients
*** Design
- Architecture
  - client-server: DNS client - local DNS server
  - client-server: local DNS server - hierachy
- Communication protocol
  - DNS queries & replies
  - Resource Records (RR)
- Transport service
  - UDP
*** Attacking
- *Impersonation* : give the wrong IP adress to the DNS client
- *DDOS* of root server of TLD : make them unavailable to the rest of the world
- *Poison the cache* of a DNS server : increase delay experienced by DNS clients
** Peer-to-Peer (P2P) applications
*** File distribution time
(times it takes to get a copy of the file to all N clients)
#+attr_html: :width 500px
[[file:images/compnet_04.png]]

- Client-server (CS) : time increases *linearly* with the number of clients
- Peer-to-peer (P2P) : time increases *sub-linearly* with the numbers of peers
#+attr_html: :width 500px
[[file:images/compnet_05.png]]

*** BitTorrent
- file divided into chunks
- peers in torrent send/receive chunks
- Each peer is given an id
****  Design
- Who gives the metadata ?
  - Server
    - peers obtains file with *metadata* from server
    - uses content to obtain the data from peers
  - Set of peers, with help from server
    - peer obtains *pointer to metadata* from servers
    - uses pointer to obtain metadata from peers
    - uses metadata to obtain the data from peers
- Who gives the ID's of the peers ?
  - server (= *tracker*) : one node that keeps track of which peers have the given content
  - set of peers, thru *distributed hash table* : distributed structure that
    keeps track of which peers have what content
- Who gives the data ?
  - set of peers
**** Circular DHT
- Each peer /only/ aware of immediate successor and predecessor
- "overlay network"
**** Peer churn
- peers may come and go (churn)
- each peers knows adress of its two sucessors
- each peer periodically pings its two sucessors to check aliveness
- if immediate sucessor leaves, choose next sucessor as new immediate sucessor
** Socket programming
*** UDP
- _no connection_ between client and servers
  - no handshake before sending data
  - sender explicitly attaches IP adress and port number of the destination to
    each packet
  - receiver extracts IP address and port number from the received packet
- Transmitted data _may be lost_ or received _out of order_
Application viewpoint: UDP provides unreliable transfer of group of bytes (“datagram”) between client and servers

*** TCP
- Client process must contact server
  - Create socket, specifying IP address, port number of server process
  - Establish connection to server TCP (handshake)
- Server process
  - Must be running already
  - Must have created TCP socket that welcomes client’s contact
- Server creates new socket whenever contacted by a client
  -Communication socket used to communicate with that particular client
  - Source IP + source port numbers used to distinguish clients
Application viewpoint: TCP provides reliable, in-order byte-stream transfer (“pipe”) between client and server
* Chapter 3
** Multiplexing and Demultiplexing
- Multiplexing at sender : handle data from multiple sockets, add transport
  header (later used for demultiplexing)
- Demultiplexing at receiver : use header to deliver received segments to
  correct socket

_Demultiplexing_

- Host receices IP datagrams
  - each datagram has source IP adress, destination IP adress
  - each datagram carries one transport-layer segment
  - each segment has source, destination port numbers
- Host use *IP addresses & port numbers* to direct segment to appropriate socket
*** Connection-less Demultiplexing (UDP)
- Socket has local port number
- Datagram to be sent into UDP socket specifies : destination IP adress +
  destination port number
- UDP socket identified by two-tuple
  - (destination IP adress, destination port number)
  - Receiver uses destination port number to direct UDP segment to the
    appropriate socket

Datagrams with _same destination port_ directed to the _same socket_ at destination
#+attr_html: :width 500px
[[file:images/compnet_06.png]]
*** Connection-oriented Demultiplexing (TCP)
- TCP socket identified by 4-tuple :
  - (source IP addresse, source port, destination IP address, destination port)
  - receiver uses all 4 values to direct segment to appropriate socket
- Server waits for connections on "welcoming socket"
  - creates new "communication socket" for each new connection
  - associates the 4-tuples with the new socket
- Example : web servers
  - persistent HTTP - different socket for each connection client
  - non-persistent HTTP - different socket for each request
#+attr_html: :width 500px
[[file:images/compnet_07.png]]
** Reliable data transfer
*** Checksum
- Redundent information
  - e.g., the binary sum of all data bytes
  - sender adds checksum to each segment
- Used to detect (+correct) data corruption
  - receiver recomputes checksum to detect corruption
  - (potentially uses checksum to correct corruption)
*** Acknowledgment
- Feedback from receiver to sender
  - receiver determines whether a segment is corrupted
  - sens positive or negative ACK
- Use to overcome data corruption
  - if receiver sends a negative ACK, sender retransmits
*** Seqence numbers
- An identifier for segments
  - sender includes a sequence number in each segement
  - receiver includes a seqence number in each ACK
- Use to disambiguate between segements
  - sender indicates whether it sends new segement
  - receiver indicates which was the last segment that was correctly received
*** Timeout + ACK
- Timeout = an expected ACK is late
  - the receiver communicates to the sender which was the last correct packet it received
- Use to overcome *data loss*
  - if the sender's timeout expires, the sender retransmits
*** RDT elements
- Checksums \rightarrow detect *data corruption* at receiver
- ACK + retransmissions \rightarrow overcome *data corruption*
- Timeouts + ACK + retransmissions \rightarrow overcome *data loss*
*** Stop and wait
- Poor sender utilization \rightarrow the sender does nothing while waiting for
  the receiver's ACK or timeout
- Time it takes : Transmission delay (L/R) + RTT (2x propagation delay)
- Server utilization : transmission of N packets /(transmission + RTT)
*** Pipelining
Better sender utilization, the sender sends up to N un-ACKed segments (N =
sliding window size)

Then, two ways :
**** Go-back-N
- The receiver accepts 0 out-of-order segmeents
- Acks are *cumulative*
  - ACK for segment 10 indicates that *all* segements
    until segment 10 have been received
- When the sender retransmits, it retransmits *all* the un-ACK-ed segments
**** Selective Repeat
- The receiver accepts N-1 out-of-order packets
- Acks are *selective*
  - Ack for segment 10 indicates that segment 10 has been received
- When the sender retransmits, it retransmits *only one* segment

** TCP
*** TCP connection
- Sockets \rightarrow pass data between app-layer process and TCP
- Bidirectional communication
- MSS: Maximum Segment Size
**** Establishmente
3-way handshake between end-systems
- Client sends connection request
- Server sends request acknowledgment
- Client send ack. of request ack.
*** Reliable data transfer
**** Seq and ACK
- Sequence number (SEQ)
  - provided by data sender
  - # of first byte of data
- Acknowledgment number (ACK)
  - provided by data receiver
  - # of oldest byte expected by receiver (cumulative)
- Both are *always present*, even when not needed
**** Timeout and retransmit
- Sender times out
  - segement corrupted, lost or delayed
  - ACK corrupted, lost or delayed
- Sender retransmits the segment with oldest un-ACKed sequence #
- Timeout
  - Bit longer than RTT
    - If too short : premature timeout, unecessary retransmissions
    - If too long : slow reaction to segment loss
  - Calculation
    - SampleRTT : measured time form segment transmission until ACK reception (ignore retransmissions)
    - EstimatedRTT = 0.875 EstimatedRTT + 0.125 SampleRTT
    - DevRTT = function(RTT variance)
    - Timeout = EstimatedRTT + 4 DevRTT
  - Empirical, conservative prediction of RTT
- Fast retransmit
  - Sender receives 3 duplicate ACKs \rightarrow segment lost or delayed
  - Sender retransmits segement with *oldest un-ACKed sequence #*
- Retransmission event
  - Sender times out
  - Sender receives 3 duplicate ACKS
- Pipelining policy
  - From Go-Back-N
    - receiver sends cumulative ACKs
    - doesn't ACK individual out-of-order segments
  - From SR
    - sender rentransmits only *one segment*
*Image TCP sender simplified (book's slides chapter 3, p.67) ?*
*** Flow control
- Receiver provides receiver window
  - equal to free space in TCP receive buffer
  - specifies how many bytes it can receive
- Sender sends up to this # of bytes \rightarrow must wait for window to "open" (sends same SEQ #, but no data, until window not null)
- Guarantees receive buffer will not overflow
- Slows down the sender
*** Connection closing
- client, server each close their side of connection \rightarrow send TCP segment with FIN bit = 1
- Respond to received FIN with ACK
*** Security
**** Impersonation
- Attack : impersonate one of the parties and provide fake content
- Defense : randomize sequence numbers \rightarrow make segment content unpredictable
**** Flood
- Attack : exhaust the SYN buffer
- Defense : get rid of SYN buffer, instead use non-forgeable ticket \rightarrow pass the state to the TCP client
*** Congestion control
**** Congestion effects
- Long queuing delays
- Ressources waste
  - Sender has to retransmit
  - routers transmit duplicate packets
  - routers transmit packets that will be dropped
**** Approches
- End-to-end congestion control (network layer)
  - no explicit feedback from network
  - congestion inferred from end-system observed loss, delay
- Network-assisted congestion control (transport layer)
  - Routers provide feeedback to end system
**** Some definitions 
- Congestion window size (CWND)
  - # of unacknowledged bytes that the sender may transmit so as to avoid creating congestion
- Bandwith-delay product
  - Max amount of traffic that the sender can transmit until he gets the first ACK = max sender window size
- Self-clocking
  - Inferring the "right" congestion widnow based on the ACKs
    - ACK = no congestion, increase window
    - No ACK = congestion, decrease window
**** TCP congestion control
- Increase window size
  - Exponentially
    - by 1 MSS for every ACKed MSS
    - when we do not expect congestion
  - Linearly
    - by 1 MSS evert RTT
    - when we expect congestion
- Basic algorithm
  - Start with exponential increase
    - when sender times out, it resets windo to MSS
    - sets congestion treshold to last window size /2
  - Transition to linear increase, when :
    - window reaches congestion threshold
    - sender receives 3 duplicates ACKs
- Terminology
  - Exponential increase = *slow start*
    - when sender times out, it resets window to MSS
    - sets congestion threshold to last window size / 2
  - Linear increase = congestion avoidance
    - window reaches congestion threshold
    - sender receives 3 duplicate ACKs
    *slide chapter 3 p.104 ?*

* Chapter 4
** Network layer function
Forwading
- *Local router* process that determines output link for each packet
- How :
  - read value from packet’s network-layer header
  - search forwarding table
Routing
- *Network wide* process that determines end-to-end path for each packet
- How :
  - centralized routing algorithm
  - distributed routing algorithm
Interplay between routing and forwarding \rightarrow routing algorithm stores in forwarding table path, forwarding table determines local forwarding

Connection setup
- *Path-wide* that sets up _connection state_ in routers \rightarrow before
  datagrams flow, two end hosts /and/ intervening routers establish virtual
  connection
** Network layer services
*** Possible services
- Guaranteed (in-order) delivery
- Guaranteed maximum delay
- Guaranteed minimum throughput
- Security (confidentiality, authenticity)
Internet provides best-effort delivery
*** Virtual-circuit networks
- “source-to-dest path behaves much like telephone circuit”
  - performance-wise
  - network actions along source-to-dest path
  - Connection state
- Useful for network-layer guarantees
- VC consists of :
  - Path from source to dest
  - VC #, one # for each link along the path
  - entries in forwarding table in routers along the path
- Forwarding state: per connection
  - VC #, input link, output link
  - populated by connection setup (must establish conneciton /before/ data can flow)VC routers maintain connection state informati
- VC routers maintain connection state information
- Not used in today's internet
*** Datagram network
- No call setup at network layer (connection-less)
- routers: no state about end-to-end connections
- Appropriate for best-effort services
- packets forwarded using destination host address
  - populated by routing process
  - Use of address range (prefix)
  - Longest prefix matching \rightarrow when looking for forwarding table entry
    for given destination address, use longest address prefix that matches destination address.
- Why this approach ?
  - Scales better \rightarrow no per-connection state in routers
  - Keeps network simpler \rightarrow no suppport for conneciton setup and
    teardown in routers
- Location-dependent addresses
  - Address embeds location information
    - address proximity implies location proximity
  - Significantly reduces forwarding state
    - per destination prefix
    - (otherwise, it would be per destination)
** Internet Protocol (IP)
*** Ip adress/prefix format
- IP address = number from 0 to 2^32 -1
- IP prefix = range of IP addresses
  - Notation using a mask : 223.1.1.0 / 24, means applying a mask with 24
    first bits to 1
*** Subnets
-IP address:
  - subnet part - high order bits (223.1.1.* or 223.1.1.0/24)
  - host part - low order bits (223.1.1.1 or 223.1.1.2,...)
- what's a subnet ?
  - device interfaces with same subnet part of IP address
  - can physically reach each other without intervening router
*** IP addresse assignment
- Each organization obtains IP prefixes
  - from its ISP or from regulatory body
- Network operator assigns IP addresses
  - to router interfaces: manually
  - to end-systems: manually or through DHCP
**** Dynamic Host Configuration Protocol (DCHP)
goal: allow host to dynamically obtain its IP address from network server when
it joins network
- can renew its lease on address in use
- allows reuse of addresses (only hold address while connected/“on”)
- support for mobile users who want to join network (more shortly)
DHCP overview:
- host broadcasts “DHCP discover” msg [optional]
- DHCP server responds with “DHCP offer” msg [optional]
- host requests IP address: “DHCP request” msg
- DHCP server sends address: “DHCP ack” msg
*** Ip fragmentation & reassembly
- When packet size exceeds MTU (Max. transfert unit)
  - router fragments it
  - adds an identifier to each fragment
- The end-system reassembles the fragments before passing the packet to the transport layer
*** Network Address Translation (NAT)
- Motivation :local network uses just one IP address as far as outside world is concerned:
  - range of addresses not needed from ISP: just one IP address for all devices
  - can change addresses of devices in local network without notifying outside world
  - can change ISP without changing addresses of devices in local network
  - devices inside local net not explicitly addressable, visible by outside world
    (a security plus)
- Resolves IP address depletion problem
- Requires per-connection state
- NAT is controversial:
  - routers should only process up to layer 3
  - violates end-to-end argument
    - NAT possibility must be taken into account by app designers, e.g., P2P applications
  - address shortage should instead be solved by IPv6

** Routing algorithm
*** Least-cost path routing
- Given: router graph & link costs
- Goal: find least-cost path from each source router to each destination router using an algorithm
*** Link state algorithm (LS)
- Dijkstra’s algorithm
  - *net topology*, link costs known to all nodes
    - accomplished via “link state broadcast”
    - all nodes have same info
  - computes least cost paths from one node (‘source”) to all other nodes
  - gives forwarding table for that node
  - iterative: after k iterations, know least cost path to k dest.’s
  - Complexity: n(n+1)/2 comparison : $O(n^2)$, more efficient implemations possible : $O(n\log n)$
- Link-state routing algorithm for source u
  - Centralized algorithm \rightarrow not distributed
  - Option #1: Router u runs the algorithm \rightarrow computes least-cost path to every other router
  - Option #2: Separate machine runs the algorithm \rightarrow computes least-cost paths between all routers
*** Distance vector algorithm (DV)
key idea:
- from time-to-time, each node sends its own distance vector estimate to neighbors
- when x receives new DV estimate from neighbor, it updates
  its own DV using B-F equation: $D_x(y) \leftarrow min_v\lbrace c(x,v) + D_v
  (y) \rbrace$ (min over all neighbors) for each node $y \in N$
- under minor, natural conditions, the estimate D x (y) converge to the actual
  least cost d x (y)
- All neighbors exchange information
- Each router checks whether it can improve current paths by leveraging the new information
- Ends when no improvement is possible

iterative, asynchronous: each local iteration caused by:
- local link cost change
- DV update message from neighbor
distributed:
- each router runs its own instance
- each node notifies neighbors only when its DV changes \rightarrow neighbors
  then notify their neighbors if necessary
each node:
- wait for (change in local link cost or msg from neighbor)
- recompute estimates
- if DV to any dest has changed, notify neighbors

**** Problem with Bellman-Ford
- Routing loop
  - z routes through y, y routes through x
  - y loses connectivity to x
  - y decides to route through z
- Can take very long to resolve
  - "bad news travels slow - “
  - count-to-infinity scenario
**** Solution
- Poisoned reverse
  - if z routes to x through y, z advertises to y that its cost to x infinite
  - y never decides to route to x through z
- Algorithm re-converges quickly
  - avoids count-to-infinity scenario
*** Comparison of LS and DV
- message complexity
  - LS: with n nodes, E links, $O(nE)$ msgs sent
  - DV: exchange between neighbors only \rightarrow convergence time varies
- speed of convergence
  - LS: $O(n^2)$ algorithm requires $O(nE)$ msgs, may have oscillations
  - DV: convergence time varies
    - may be routing loops
    - count-to-infinity problem
- robustness: what happens if router malfunctions?
  - LS:
    - node can advertise incorrect link cost
    - each node computes only its own table
  - DV:
    - DV node can advertise incorrect path cost
    - each node’s table used by others \rightarrow error propagate thru network
** Routing in the Internet
*** Challenges
- Scale
  - link-state would cause flooding
  - distance-vector would not converge
- Administrative autonomy
  - an ISP may not want to do least-cost routing
  - may want to hide its link costs from the world
*** intra-AS routing
- aggregate routers into regions, “autonomous systems” (AS)
- routers in same AS run same routing protocol
  - “intra-AS” routing protocol \rightarrow determines the path between every pair of routers in the same AS
  - routers in different AS can run different intra-AS routing protocol
- gateway router:
  - at “edge” of its own AS
  - has link to router in another AS
*** Inter-AS routing
- Run by all Internet routers
- Determines the path from every router to every foreign AS
  - not exactly so: determines the path from each router to each IP prefix advertized by a foreign AS
*** Internet routing protocol
**** Intra-AS 
- Routing Information Protocol (RIP) \rightarrow distance vector algorithm
- Open Shortest Path First (OSPF) \rightarrow LS algorithm
**** Inter-AS : Border Gateway Protocol (BGP)
- BGP points
  - A router distributes reachability information to external routers through e-BGP.
  - A router distributes external reachability information to other local routers through i-BGP.
- BGP route selection
  - Route that crosses fewer ASes
  - Route that crosses fewer local routers
  - Route with highest local preference
* Chapter 5
** Terminology
- nodes: hosts, switches, routers
- link: communication channel that connects adjacent nodes
  - wired links
  - wireless links
- frame: link-layer “packet”
- Hardware: network adaptor (NIC)

*data-link layer* has responsibility of transferring datagram from one node to
*physically adjacent* node over a link
** Link Layer Services
- Error detection
  - detect bit errors caused by signal attenuation, noise
  - drop frames with bit errors
- Reliable data delivery
  - error detection + correction/retransmission
  - used for links with high-error rate (wireless)
- Link access
  - how to share the same link with other nodes
- Flow control
  - pacing between adjacent sending and receiving nodes
** Error detection and correction
- EDC= Error Detection and Correction bits (redundancy)
- D = Data protected by error checking, may include header fields
- Error detection not 100% reliable!
  - protocol may miss some errors, but rarely
  - larger EDC field yields better detection and correction
*** Implemantations
- Single bit parity: detect single bit errors
- Two-dimensional bit parity: detect and correct single bit errors
- Cyclic Redundancy Check (CRC)
  - more powerful error-detection than parity checking
  - widely used in practice: Ethernet, WiFi
** Media Access Control (MAC)
two types of “links”: 
- point-to-point
  - PPP for dial-up access 
  - point-to-point link between Ethernet switch, host
- broadcast (shared wire or medium) 
  - old-fashioned Ethernet 
  - upstream HFC 
  - 802.11 wireless LAN
*** Multiple access protocols
- Given single shared broadcast link of rate R
- The problem 
  - interference = two or more simultaneous transmissions 
  - collision = node receives two or more signals at the same time
- An ideal multiple access protocol 
  - when only one node wants to transmit, it can send at rate R 
  - when N nodes want to transmit, each can send at average rate R/N 
  - simple, fully decentralized
*** MAC strategies
**** Channel partitioning
- TDMA: time divided in equal frames and slots
- FDMA: frequency spectrum divided into frequency bands
- Efficient at high load. Inefficient at low load
**** Random access
- if single node - transmit at full rate R bps
- if N nodes - transmit at well below ideal R/N bps each (collisions, empty slots)
- random access MAC protocol specifies:
  - how to detect collisions
  - how to recover from collisions (e.g., via delayed retransmissions)
Efficient at low load. Inefficient at high load.

Exemple :
CSMA (carrier sense multiple access)
- listen before transmit:
  - if channel sensed idle: transmit entire frame 
  - if channel sensed busy, defer transmission
- collisions can still occur:
  - propagation delay means two nodes may not hear
    each other’s transmission
  - In case of collision, entire packet transmission time wasted
  - distance & propagation delay play role in in determining collision
    probability
- Collision detection
  - Sense the channel before transmitting
    - if channel sensed idle, transmit
    - if channel sensed busy, defer transmission
  - If a collision is detected
    - abort transmission
    - defer transmission
  - Algorithm
    1) NIC receives datagram from network layer, creates frame
    2) If NIC senses channel idle, starts frame transmission. If NIC senses
       channel busy, waits until channel idle, then transmits.
    3) If NIC transmits entire frame without detecting another transmission, NIC
       is done with frame!
    4) If NIC detects another transmission while transmitting, aborts and sends
       jam signal
    5) After aborting, NIC enters exponential backoff: more collisions
       \rightarrow longer wait interval
**** Taking turns
- Polling: master “invites” slave to transmit
  - Main concerns 
    - polling overhead 
    - single point of failure (master)
- Token passing: control token passed from one node to the next sequentially
  - Main concerns 
    - token overhead 
    - single point of failure (token)
** Link-layer forwarding++
*** MAC Addresses and Address Resolution Protocol (ARP)
- MAC Addresses
  - Used to move frames between link-layer nodes \rightarrow one address per NIC
  - Format: 48 bit address, flat \rightarrow usually shown in hexadecimal format
- ARP
  - How to determine interface’s MAC address, knowing its IP address?
  - Source broadcasts request for destination’s MAC address
  - Stores response in local ARP table < IP address; MAC address; TTL>
*** Ethernet
- The dominant wired LAN technology
  - First widely used LAN technology
  - Simpler, cheaper than token LANs and ATM
  - Kept up with speed race: 10 Mbps – 100 Gbps
**** Ethernet services
- Connectionless 
  - no handshaking between sending and receiving NICs
- Unreliable 
  - receiving NIC does not send ACKs or NACKs to sending NIC 
  - recover dropped frames only if sender uses higher layer “rdt” (TCP)
- MAC protocol 
  - CSMA/CD with exponential backoff
**** Ethernet Frame Structure
- Sending adapter encapsulates datagram in Ethernet frame
- preamble: 7 x 10101010 followed by 1 x 10101011
  - synchronize sender, receiver clock rates
- addresses: 48 bit source, source/destination MAC address
  - receive frame only if destination matches or broadcast
- type: indicates higher layer protocol: mostly IP, others possible
- CRC: cyclic redundancy check at receiver
**** Ethernet Physical Topology
- bus: popular in the mid 90s
  - all nodes in same collision domain (frames can collide)
- star: prevails today
  - active switch in the middle - each “spoke” in a separate
    collision domain (no collisions)
*** Link-layer Switch
- Forwards frames within LAN 
  - determines output port based on destination MAC address 
  - similar to router forwarding process

- Self-learning 
  - forwarding table populated automatically 
  - no need for manual configuration or routing protocol
**** Self learning
When a frame is received at the switch:
1. Record pair (source MAC address; incoming link)
2. Index forwarding table using destination MAC address
3. If entry found:
   - if destination on link from which frame arrived drop frame
   - else forward frame on link indicated by entry
4. (else) If entry not found:
   - flood: forward on all links except the arriving interface
**** Switches vs routers
Both are store-and-forward
- routers: network-layer devices (examine network-layer headers)
- switches: link-layer devices (examine link-layer headers)
Both have forwarding tables 
- routers: using routing 
- switches: using self-learning
* Chapter 8
** Security properties
- Confidentiality
  - only the sender and the receiver understand the contents of the message
- Authenticity
  - the message is from whom it claims to be
- Integrity
  - the message was not changed along the way
** Building blocks
*** Symmetric key cryptography
- Alice and Bob share the same key \rightarrow used both for the encryption and decryption algorithm
- Used to “scramble” the plaintext
  - stream ciphers & block ciphers
  - RC4, AES, Blowfish

Challenge: how to share a key?
- out of band
- not always an option
*** Asymmetric key cryptography
- Alice and Bob use different keys
  - public (key+) and private (key-) key
- There is a special relationship between them
  - key-{ key+{ plaintext } } = plaintext
  - key+{ key-{ plaintext } } = plaintext
  - RSA, DSA

Challenge: computationally expensive
- sophisticated encryption/decryption algorithms based on number theory
*** Cryptographic hash function
- Maps larger input to smaller hash
- Hash should not reveal information on input
- Should be hard to identify 2 inputs that lead to the same hash
** Providing confidentiality
- With symmetric key crypto
  - Alice encrypts message with shared key
  - only Bob can decrypt it

- With asymmetric key crypto
  - Alice encrypts message with Bob’s public key
  - only Bob can decrypt it (with his private key)
  - but beware of man-in-the-middle attacks
** Providing authenticity
- With symmetric key crypto
  - Alice appends hash of message + shared key
  - Bob verifies that it is correct (using shared key)

- With asymmetric key crypto
  - Alice encrypts hash of message with her private key, appends to unencrypted message
  - Bob verifies that it is correct (using Alice’s public key)
 
- Nonce for avoiding replay attacks
  - Bob sends Alice a nonce (random number)
  - Alice appends hash of message + shared key + nonce
 
- Still one issue: man in the middle attack
- Manuel poses as Alice (to Bob) and as Bob (to Alice) difficult to detect
  - Bob receives everything that Alice sends, and vice versa. (e.g., so Bob,
    Alice can meet one week later and recall conversation!)
  - problem is that Manul receives all messages as well!
** Providing integrity
- cryptographic technique analogous to hand-written signatures:
  - sender (Bob) digitally signs document, establishing he is document owner/creator.
  - verifiable, nonforgeable: recipient (Alice) can prove to someone that Bob,
    and no one else (including Alice), must have signed document
*** Public key certification
- Trusted certificate authority (CA) digitally signs that key+ is Bob’s public
  key using the CA’s private key
- CA’s public key is obtained out of band \rightarrow web browsers pre-configured with CA public keys

** Securing email
*** Confidentiality
Alice wants to send confidential e-mail, m, to Bob.

Alice:
- generates random symmetric private key, K_S
- encrypts message with K_S (for efficiency)
- also encrypts K_S with Bob’s public key
- sends both K_S(m) and K_B(K_S) to Bob

Bob:
- uses his private key to decrypt and recover K_S
- uses K_S to decrypt K_S(m) to recover m
*** Authenticity and Integrity
Alice wants to provide sender authentication message integrity

- Alice digitally signs message
- sends both message (in the clear) and digital signature
*** All of them
Alice wants to provide secrecy, sender authentication, message integrity.

Alice uses *three keys*: her private key, Bob’s public key, newly created symmetric key
** Securing TCP
- Server sends its certificate, includes its public key
- Client creates and sends a shared master key, encrypts it with server’s public key
- Both use master key to create 4 session keys
  - 1 key for encrypting client \rightarrow server data
  - 1 key for creating MAC for client \rightarrow server data
  - same for server \rightarrow client data

- Client organizes data in records, each record has a sequence number
- Creates MAC for each record + sequence #, using one of the 4 session keys
- Encrypts the data + MAC for each record, using (another) one of the 4 session keys
** Securing IP
- 2 IP routers establish a “secure tunnel” \rightarrow usually between branch offices of a company
- Source encrypts each IP packet using a shared key
- Source creates MAC for encrypted IP packet using another shared key
*** Key ideas
- Combination of symmetric/asymmetric keys
  - asymmetric key crypto to exchange shared keys
  - symmetric key crypto for confidentiality,authenticity, & integrity
  - symmetric key crypto is faster
- Seq. numbers to avoid reordering attacks
  - organize data in records with seq. numbers
  - compute MAC on record data + seq. number
** Firewall
isolates organization’s internal net from larger Internet, allowing some packets
to pass, blocking others
* HW1
Imagine d_end-to-end between 2 links is D, imagine now N links, to send P
packets, time taken is N*D+(P-1)*D, in words, time for the first packet to
reach destination + time for all the other packets to go from last link to destination

Max user in a FDM of total speed S and required speed s_req : S/s_req

Max user for TDM : Suppose that the duration of a frame is T sec. Suppose also
that the number of timeslots in the frame is U. Since the same slot is
assigned always to the same user, U is also equal to the number of users.
Therefore, a user that requires s_req transmitting rate, has to send (T
∙ s_req) kbits of data during the timeslot which is assigned to him. On the
other hand, one may send up to S ∙ T/U kbits during that timeslot. So T ∙
s_req \le S ∙ T/U \Rightarrow U \le S/s_req

Suppose a system with N users, probability that a user is transmitting is p,
probability that n user use the link simultaneously : $\binom{N}{n}$ p^n (1-p)^{N-n}

Maximum number of bit on a link of speed R (continuous file sending) :
R∙d_prop
* HW2
Time to get ip-address from name (cache empty), with n servers and constant
delay of D between any two machines (RTT=2D) : 2nD. Now if cache contains name : 2D

Non persistent HTTP routine : TCP-handshake-TCP-handshake reply (1RTT), GET
page.html-200 OK (page.html) (1RTT) and then for each element to load :
TCP-handshake-TCP-handshake reply (1RTT) + GET object... - 200 OK (object...)
(1RTT). So time to load a page with n objects = (n+1)*RTT (Where you may need
to add DNS delay)

Non persistent HTTP in parallel, n=pk objects, p parallel connections : We
need to do 2(n/p) = 2k roundtrip, so time is : (DNS delay) + 2RTT (= initial
handshake + get page.html) + 2k RTT

Persistent HTTP single connection : (DNS delay) + 2 RTT (=initial handshake +
get page.html) + RTT (only if transmission delay for sending n requests and n
replies is negligeable)
